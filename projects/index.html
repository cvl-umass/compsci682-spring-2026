---
description: Project
---
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- HTML4 meta tags forcing no-caching -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate" />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />

    <link rel="icon" href="{{site.baseurl}}/favicon.ico">

    <title>COMPSCI 682 Neural Networks: A Modern Introduction</title>

    <!-- Bootstrap core CSS -->
    <link href="{{site.baseurl}}/assets/css/bootstrap.min.css" rel="stylesheet">

    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link href="{{site.baseurl}}/assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="{{site.baseurl}}/assets/css/offcanvas.css" rel="stylesheet">

    <!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
    <!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
    <script src="{{site.baseurl}}/assets/js/ie-emulation-modes-warning.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>
    <nav class="navbar navbar-fixed-top navbar-custom">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <!--<a class="navbar-brand" href="https://www.cics.umass.edu/">COMPSCI697L</a>-->
          <a class="navbar-brand" href="https://www.cics.umass.edu/"><img style="max-height:15px; margin-top: 1px;"
             src="{{site.baseurl}}/assets/fig/umasslogo2.png"></a>
          <!--<a class="navbar-brand" href="#">COMPSCI697L</a>-->
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="{{site.baseurl}}/index.html">Home</a></li>
            <li><a href="{{site.baseurl}}/lectures.html">Lectures</a></li>
            <li><a href="{{site.baseurl}}/notes/">Notes</a></li>
            <li><a href="{{site.baseurl}}/assignments.html">Assignments</a></li>
            <li><a href="{{site.baseurl}}/policies/">Policies</a></li>
            <li class="active"><a href="{{site.baseurl}}/projects/">Project</a></li>
            <li><a href="{{site.baseurl}}/officehours/">Office Hours</a></li>
          </ul>
        </div><!-- /.nav-collapse -->
      </div><!-- /.container -->
    </nav><!-- /.navbar -->

    <div class="container">
<h2>COMPSCI 682 Neural Networks: A Modern Introduction</h2>
        <div class="panel panel-success">
            <div class="panel-heading">
                <h3 class="panel-title">Acknowlegements</h3>
            </div>
            <div class="panel-body">
                These project guidelines originally accompany the Stanford CS class <a href="http://cs231n.stanford.edu/">CS231n</a>, and are now provided here for
                the UMass class COMPSCI 682 with minor changes reflecting our course contents. Many thanks to Fei-Fei Li and Andrej Karpathy for graciously letting us use their course materials!
            </div>
        </div>
<!--
        <div class="panel panel-info">
            <div class="panel-heading">
                <h3 class="panel-title">Announcements</h3>
            </div>
            <div class="panel-body">
                <ul>
                    <li>All project reports are now available <a href="https://docs.google.com/spreadsheets/d/10rbnBZGXzfDGnTRM8h4Q660ZZ731RSQosZr-RqtlUhU/edit?usp=sharing">here</a>. Check out all the cool projects from your classmates!</li>
                </ul>
            </div>
        </div>
-->

  <h2>Important Dates (tentative)</h2>
  Project proposal due: Tuesday, March 31<br>
  Final write-up due: Tuesday, May 12<br>
  Presentations: TBD<br>

  <h2>Overview</h2>
  <p>The course project is an opportunity for you to apply what you have learned in class to a problem of your interest.</p>

  <p>Your are encouraged to select a topic and work on your own project. Potential projects usually fall into these two tracks:</p>
  <ul>
    <li><strong>Applications.</strong> If you're coming to the class with a specific background and interests (e.g. biology, engineering, physics), we'd love to see you apply deep neural networks to problems related to your particular domain of interest. Pick a real-world problem and apply deep neural networks to solve it. </li>
    <li><strong>Models.</strong> You can build a new model (algorithm) with deep neural networks, or a new variant of existing models, and apply it to tackle vision tasks. This track might be more challenging, and sometimes leads to a piece of publishable work.</li>
  </ul>

  <p>Here you can find some sample project ideas:</p>

  <ul>
    <li><a href="https://docs.google.com/spreadsheets/d/1KwJFP3KwPCpLFVmBHympqBxI6xzxSgA9g6UzWp0ursM/edit?usp=sharing">Sample project ideas from TAs, Fall 2024 (Google docs)</a></li>
    <li><a href="https://docs.google.com/spreadsheets/d/14oMv9oC1mnWrBzgJgTO0GbJMDXFt2y1r2j0kAzf7k1s/edit#gid=0">Sample project
    ideas from TAs, Fall 2023 (Google Docs)</a></li>
    <li><a href="https://docs.google.com/document/d/1ZAxeXT-Wavxg5RGMu8eYeebRH5uD8BVaY9PcZ70HgOk/edit?usp=sharing">Sample
    project ideas from Prof. Erik Learned-Miller last semester (Google Docs)</a></li>
    <li><a href="http://cs231n.stanford.edu/2017/reports.html">[Stanford cs231n project reports: spring 2017]</a></li>
    <li><a href="http://cs231n.stanford.edu/2016/reports.html">[Stanford cs231n project reports: winter 2016]</a></li>
    <li><a href="http://cs231n.stanford.edu/2015/reports.html">[Stanford cs231n project reports: winter 2015</a></li>
  </ul>

  <p>To inspire ideas, you might look at recent deep learning publications from top-tier vision conferences, as well as other resources below.</p>
  <ul>
    <li><a href="https://github.com/kjw0612/awesome-deep-vision">Awesome Deep Vision</a></li>
    <li><a href="https://openaccess.thecvf.com/CVPR2023?day=all">CVPR</a>: IEEE Conference on Computer Vision and Pattern Recognition</li>
    <li><a href="https://openaccess.thecvf.com/ICCV2019">ICCV</a>: International Conference on Computer Vision</li>
    <li><a href="http://www.eccv2016.org/main-conference/">ECCV</a>: European Conference on Computer Vision</li>
    <li><a href="https://papers.nips.cc/">NIPS</a>: Neural Information Processing Systems</li>
    <li><a href="https://openreview.net/group?id=ICLR.cc/2023/Conference">ICLR</a>: International Conference on Learning Representations</li>
    <li><a href="http://www.kaggle.com/">Kaggle challenges</a>: An online machine learning competition website. For example, a <a href="https://www.kaggle.com/c/yelp-restaurant-photo-classification">Yelp classification challenge</a>.</li>
  </ul>

  <p>For applications, this type of projects would involve careful data preparation, an appropriate loss function, details of training and cross-validation and good test set evaluations and model comparisons. Don't be afraid to think outside of the box. Some successful examples can be found below:</p>
  <ul>
    <li><a href="http://arxiv.org/abs/1412.3409">Teaching Deep Convolutional Neural Networks to Play Go</a></li>
    <li><a href="http://arxiv.org/abs/1312.5602">Playing Atari with Deep Reinforcement Learning</a></li>
    <li><a href="http://blog.kaggle.com/2014/04/18/winning-the-galaxy-challenge-with-convnets/">Winning the Galaxy Challenge with convnets</a></li>
  </ul>

  Deep neural networks also run in real time on mobile phones and Raspberry Pi's - feel free to go the embedded way. You may find <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android">this TensorFlow demo on Android</a> helpful. </p>

  <p>For models, deep neural networks have been successfully used in a variety of computer vision and NLP tasks. This type of projects would involve understanding the state-of-the-art vision or NLP models, and building new models or improving existing models. The list below presents some papers on recent advances of deep neural networks in the computer vision community.</p>
  <ul>
    <li><strong>Object recognition</strong>: <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">[Krizhevsky et al.]</a>, <a href="http://arxiv.org/abs/1409.0575">[Russakovsky et al.]</a>, <a href="http://arxiv.org/abs/1409.4842">[Szegedy et al.]</a>, <a href="http://arxiv.org/abs/1409.1556">[Simonyan et al.]</a>, <a href="http://arxiv.org/abs/1406.4729">[He et al.]</a></li>
    <li><strong>Object detection</strong>: <a href="http://arxiv.org/abs/1311.2524">[Girshick et al.]</a>, <a href="http://arxiv.org/abs/1312.6229">[Sermanet et al.]</a>, <a href="http://arxiv.org/abs/1312.2249">[Erhan et al.]</a></li>
    <li><strong>Image segmentation</strong>: <a href="http://arxiv.org/abs/1411.4038">[Long et al.]</a></li>
    <li><strong>Video classification</strong>: <a href="https://cs.stanford.edu/people/karpathy/deepvideo/">[Karpathy et al.]</a>, <a href="http://arxiv.org/abs/1406.2199">[Simonyan and Zisserman]</a></li>
    <li><strong>Scene classification</strong>: <a href="http://places.csail.mit.edu/">[Zhou et al.]</a></li>
    <li><strong>Face recognition</strong>: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Taigman_DeepFace_Closing_the_2014_CVPR_paper.pdf">[Taigman et al.]</a></li>
    <li><strong>Depth estimation</strong>: <a href="http://www.cs.nyu.edu/~deigen/depth/">[Eigen et al.]</a></li>
    <li><strong>Image-to-sentence generation</strong>: <a href="https://cs.stanford.edu/people/karpathy/deepimagesent/">[Karpathy and Fei-Fei]</a>, <a href="http://arxiv.org/abs/1411.4389">[Donahue et al.]</a>, <a href="http://arxiv.org/abs/1411.4555">[Vinyals et al.]</a></li>
    <li><strong>Visualization and optimization</strong>: <a href="http://arxiv.org/pdf/1312.6199v4.pdf">[Szegedy et al.]</a>, <a href="http://arxiv.org/abs/1412.1897">[Nguyen et al.]</a>, <a href="http://arxiv.org/abs/1311.2901">[Zeiler and Fergus]</a>, <a href="http://arxiv.org/abs/1412.6572">[Goodfellow et al.]</a>, <a href="http://arxiv.org/abs/1312.6055">[Schaul et al.]</a></li>
  </ul>

  <p>We also provide a list of popular computer vision datasets:</p>

  <p></p>
  <ul>
    <li><a href="http://www.cvpapers.com/datasets.html">Meta Pointer: A large collection organized by CV Datasets.</a></li>
    <li><a href="http://riemenschneider.hayko.at/vision/dataset/">Yet another Meta pointer</a></li>
    <li><a href="http://image-net.org/">ImageNet</a>: a large-scale image dataset for visual recognition organized by <a href="http://wordnet.princeton.edu/">WordNet</a> hierarchy</li>
    <li><a href="http://groups.csail.mit.edu/vision/SUN/">SUN Database</a>: a benchmark for scene recognition and object detection with annotated scene categories and segmented objects</li>
    <li><a href="http://places.csail.mit.edu/">Places Database</a>: a scene-centric database with 205 scene categories and 2.5 millions of labelled images</li>
    <li><a href="http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2.html">NYU Depth Dataset v2</a>: a RGB-D dataset of segmented indoor scenes</li>
    <li><a href="http://cocodataset.org/">Microsoft COCO</a>: a new benchmark for image recognition, segmentation and captioning</li>
    <li><a href="http://www.multimediacommons.org/">Flickr100M</a>: 100 million creative commons Flickr images</li>
    <li><a href="http://vis-www.cs.umass.edu/lfw/">Labeled Faces in the Wild</a>: a dataset of 13,000 labeled face photographs</li>
    <li><a href="http://human-pose.mpi-inf.mpg.de/">Human Pose Dataset</a>: a benchmark for articulated human pose estimation</li>
    <li><a href="http://www.cs.tau.ac.il/~wolf/ytfaces/">YouTube Faces DB</a>: a face video dataset for unconstrained face recognition in videos</li>
    <li><a href="http://crcv.ucf.edu/data/UCF101.php">UCF101</a>: an action recognition data set of realistic action videos with 101 action categories</li>
    <li><a href="http://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/">HMDB-51</a>: a large human motion dataset of 51 action classes</li>
  </ul>
  <p></p>

  <h2>Grading Policy (tentative)</h2>
  <pre>
  Project: 25% of final grade
  - Proposal: 5% of final grade
  - Final Report: 15% of final grade
     write-up (40% of Final Report):
      •  clarity, structure, language, references
      •  background literature survey, good understanding of the problem
      •  good insights and discussions of methodology, analysis, results, etc.
     technical (30% of Final Report):
      •  correctness
      •  depth
      •  innovation
     evaluation and results (30% of Final Report):
      •  sound evaluation metric
      •  thoroughness in analysis and experimentation
      •  results and performance
  - Project Presentation: 5% of final grade
  </pre>

  <h2>Project Proposal</h2>
  Your project proposal should be between 2-3 pages using the template (<a href="template/main.pdf">pdf</a>, <a href="template/CS682_2024_project_report_template.zip">latex source</a>). The following is a suggested structure for your report:
  <p>
  </p>
    <ul>
      <li><b>Title, Author(s):</b> Pick a relevant title and include all the members in your group as authors.</li>
      <li><b>Introduction:</b> This section introduces your problem, motivation, and the overall plan. It should describe your problem precisely specifying the dataset to be used, expected results and evaluation.</li>
      <li><b>Related work:</b> A literature survey of past work on this topic.
        Introduce the baselines you will compare to and the weakness you plan to address.
        You should also describe what data will you use. If you are collecting new datasets, how do you plan to collect them? If the datasets are huge what compute resources are you using?
      <li><b>Technical Approach:</b> Describe the methods you intend to apply to solve the given problem. If there are existing implementations, will you use them and how? How do you plan to improve or modify such implementations?</li>
      <li><strong>Evaluation Metric:</strong> How will you evaluate your results? Qualitatively, what kind of results do you expect (e.g. plots or figures)? Quantitatively, what kind of analysis will you use to evaluate and/or compare your results (e.g. what performance metrics or statistical tests)?</li>
      <li><b>Preliminary Results:</b> Share any preliminary results if you have them.
    </ul>
  <p>
    <strong>Submission</strong>: Please upload a PDF file to Gradescope. Please coordinate with your teammates to <strong>submit under one of your accounts</strong> and add your teammates to the submission. If there are multiple submissions from a group we will grade one randomly.
  </p>

  <h2>Final Submission</h2>
  Your final write-up should be between <b>6-8</b> pages using the same template as the milestone report (<a href="template/main.pdf">pdf</a>, <a href="template/CS682_2024_project_report_template.zip">latex source</a>) and fully flesh out the sections in the milestone.
  After the class, we may post all the final reports online so that you can read about each others' work. If you do not want your writeup to be posted online, then please let us know at least a week in advance of the final writeup submission deadline.<br>

  <h2>Project Presentation</h2>
  <p>
  We will either have a presentation or poster toward the end of the class. More details on the presentation format will be provided later in the semester.
</p>


  <!-- <br>Examples of things to put in your supplementary material:
  <ul>
    <li>Source code (if your project proposed an algorithm, or code that is relevant and important for your project.).</li>
    <li>Cool videos, interactive visualizations, demos, etc.</li>
  </ul>
  Examples of things to not put in your supplementary material:
  <ul>
    <li>All of Caffe source code.</li>
    <li>Various ordinary data preprocessing scripts.</li>
    <li>Any code that is larger than 10MB.</li>
    <li>Model checkpoints.</li>
    <li>A computer virus.</li>
  </ul> -->


  <!-- <h2>Example Project Reports</h2>
  <a href="https://docs.google.com/spreadsheets/d/15OD2rXSUjv2fKLanevtMlaD2NteiFwF1_bv1ziyJ2Xs/edit?usp=sharing">COMPSCI 682 (2017 Fall) projects (only the project titles are available)</a><br>
  <a href="https://docs.google.com/spreadsheets/d/10rbnBZGXzfDGnTRM8h4Q660ZZ731RSQosZr-RqtlUhU/edit?usp=sharing">COMPSCI 697L (2016 Fall) projects</a><br>
  <a href="http://vision.stanford.edu/teaching/cs231n/reports.html">Stanford CS231n (2015 Winter) projects</a>.
  <br> -->

  <h2>Collaboration Policy</h2>
  You can work in teams of 2 or 3 people. Individual projects or larger group sizes are permitted only in exceptional circumstances (e.g., remote students, etc) and need prior permission from the instructor.
  We do expect that projects done with 3 people have more impressive writeup and results than 2 person projects.

  <h2>Honor Code</h2>
  You may consult any papers, books, online references, or publicly available implementations for ideas and code that you may want to incorporate into your strategy or algorithm, so long as you clearly cite your sources in your code and your writeup. However, under no circumstances may you look at another group’s code or incorporate their code into your project.

  </div><!--/.container-->
    <footer class="site-footer">
      <div class="wrap">
        <div class="footer-col-1 column">
          <ul>
            <li><a href="https://github.com/cvl-umass/compsci682-fall-2024">
              <span class="icon github">
                <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                   viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                  <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                  c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                  c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                  c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                  C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                  c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                  c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                  c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                  c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
                </svg>
              </span>
              <span class="username">compsci682-fall-2024</span>
            </a>
            </li>
            <!-- <li>
              <a href="mailto:compsci682@gmail.com">compsci682@gmail.com</a>
            </li> -->
          </ul>
        </div>
        <div class="footer-col-2 column">

        </div>

        <div class="footer-col-3 column">

        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
    <script src="{{site.baseurl}}/assets/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="{{site.baseurl}}/assets/js/ie10-viewport-bug-workaround.js"></script>
    <script src="{{site.baseurl}}/assets/js/offcanvas.js"></script>
  </body>
</html>
